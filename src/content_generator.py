"""
Content Generator - AI-Powered Content Generation

This module generates SEO-optimized content based on Excel output files.
Features:
- Read topics and headings from Excel files
- Generate content for each heading with custom word counts
- Generate introduction and conclusion
- Support for multiple AI models
- Save content to Excel, Word, and HTML formats
"""

import logging
import pandas as pd
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
import json
import re

logger = logging.getLogger(__name__)


class ContentGenerator:
    """Generates SEO-optimized content for headings."""
    
    # Persian SEO content generation prompt for headings
    HEADING_PROMPT_TEMPLATE = """
**Ù†Ù‚Ø´ Ø´Ù…Ø§:** 
ØªÙˆ ÛŒÚ© Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒØ³Øª Ùˆ Ù…ØªØ®ØµØµ ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ÛŒ SEO Ù‡Ø³ØªÛŒ Ú©Ù‡ Ø¨Ø±Ø§ÛŒ ÙˆØ¨â€ŒØ³Ø§ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ Ø¯Ø± ÙØ±ÙˆØ´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ÛŒÙ†ØªØ±Ù†ØªÛŒ ÙØ¹Ø§Ù„ÛŒØª Ù…ÛŒâ€ŒÚ©Ù†ÛŒ. ØªØ®ØµØµ Ø§ØµÙ„ÛŒ ØªÙˆØŒ Ø§ÛŒØ¬Ø§Ø¯ Ø§Ù‚ØªØ¯Ø§Ø± Ù…ÙˆØ¶ÙˆØ¹ÛŒ (Topical Authority) Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ø®ÙˆØ§Ù†Ù†Ø¯Ù‡ Ø¨Ù‡ Ø®Ø±ÛŒØ¯Ø§Ø± Ø§Ø² Ø·Ø±ÛŒÙ‚ Ù…Ø­ØªÙˆØ§ÛŒ Ù‡Ø¯ÙÙ…Ù†Ø¯ Ø§Ø³Øª.
 
**ÙˆØ±ÙˆØ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡:** 
- **Ù†Ø§Ù… ÙˆØ¨â€ŒØ³Ø§ÛŒØª:** {project_name}
- **Ù…ÙˆØ¶ÙˆØ¹ Ø§ØµÙ„ÛŒ Ù…Ù‚Ø§Ù„Ù‡:** {main_topic}
- **Ù‡Ø¯ÛŒÙ†Ú¯ ÙØ¹Ù„ÛŒ:** {current_heading}
- **Ù‡Ø¯ÛŒÙ†Ú¯â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· Ø¯Ø± Ø§ÛŒÙ† Ù…Ù‚Ø§Ù„Ù‡:** {related_headings}

**Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„:**
Ù…Ø­ØªÙˆØ§ÛŒ ØªØ®ØµØµÛŒØŒ Ú©Ø§Ù…Ù„ Ùˆ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø±Ø§ **ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ù‡Ø¯ÛŒÙ†Ú¯ "{current_heading}"** Ø¨Ù†ÙˆÛŒØ³.

**Ø§Ù„Ø²Ø§Ù…Ø§Øª:**
- Ø·ÙˆÙ„ Ù…Ø­ØªÙˆØ§: Ø­Ø¯ÙˆØ¯ {word_count} Ú©Ù„Ù…Ù‡
- Ù„Ø­Ù†: Ø­Ø±ÙÙ‡â€ŒØ§ÛŒØŒ Ù…Ø«Ø¨Øª Ùˆ Ø¬Ø°Ø§Ø¨
- Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ SEO: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø·Ø¨ÛŒØ¹ÛŒ Ø§Ø² Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ
- Ø³Ø§Ø®ØªØ§Ø±: Ø´Ø§Ù…Ù„ Ø²ÛŒØ±Ø¹Ù†Ø§ÙˆÛŒÙ† H3 Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²ØŒ Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ùâ€ŒÙ‡Ø§ØŒ Ù„ÛŒØ³Øªâ€ŒÙ‡Ø§
- E-E-A-T: ØªØ®ØµØµØŒ ØªØ¬Ø±Ø¨Ù‡ØŒ Ø§Ø¹ØªØ¨Ø§Ø± Ùˆ Ø§Ø¹ØªÙ…Ø§Ø¯Ù¾Ø°ÛŒØ±ÛŒ
- ØªÙ†ÙˆØ¹ Ø¯Ø± Ø¬Ù…Ù„Ø§Øª: ØªØ±Ú©ÛŒØ¨ Ø¬Ù…Ù„Ø§Øª Ú©ÙˆØªØ§Ù‡ Ùˆ Ø¨Ù„Ù†Ø¯
- Ø·Ø¨ÛŒØ¹ÛŒ Ø¨ÙˆØ¯Ù†: Ø¹Ø¨Ø§Ø±Ø§Øª Ù…Ø­Ø§ÙˆØ±Ù‡â€ŒØ§ÛŒ Ù…Ù„Ø§ÛŒÙ…ØŒ Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒ
- **Ù…Ù‡Ù…:** Ø¨Ø¯ÙˆÙ† Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ ÛŒØ§ Ø¬Ù…Ø¹â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø¨Ø®Ø´ - ÙÙ‚Ø· Ù…Ø­ØªÙˆØ§ÛŒ Ø§ØµÙ„ÛŒ

**Ø®Ø±ÙˆØ¬ÛŒ:**
ÙÙ‚Ø· Ù…ØªÙ† Ù…Ø­ØªÙˆØ§ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ù‡Ø¯ÛŒÙ†Ú¯ Ø¨Ù†ÙˆÛŒØ³ (Ø¨Ø¯ÙˆÙ† Ø°Ú©Ø± Ø®ÙˆØ¯ Ù‡Ø¯ÛŒÙ†Ú¯ Ùˆ Ø¨Ø¯ÙˆÙ† Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ). Ù…Ø­ØªÙˆØ§ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ ØªÚ¯â€ŒÙ‡Ø§ÛŒ HTML ÙØ±Ù…Øªâ€ŒØ¨Ù†Ø¯ÛŒ Ø´ÙˆØ¯:
- Ø¨Ø±Ø§ÛŒ Ø²ÛŒØ±Ø¹Ù†Ø§ÙˆÛŒÙ† Ø§Ø² <h3> Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
- Ø¨Ø±Ø§ÛŒ ØªØ§Ú©ÛŒØ¯ Ø§Ø² <strong> Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†  
- Ø¨Ø±Ø§ÛŒ Ù„ÛŒØ³Øªâ€ŒÙ‡Ø§ Ø§Ø² <ul> Ùˆ <li> Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†

Ù‡Ù…Ú†Ù†ÛŒÙ†ØŒ Ø¯Ø± Ù…ØªÙ† Ù†Ù‡Ø§ÛŒÛŒØŒ Ø¨Ù‡ ØµÙˆØ±Øª ØªØµØ§Ø¯ÙÛŒ (Ø­Ø¯ÙˆØ¯ Û²Û°-Û³Û°% Ù…ÙˆØ§Ø±Ø¯) Ø¨Ø±Ø®ÛŒ Ù†ÛŒÙ…â€ŒÙØ§ØµÙ„Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø­Ø°Ù Ú©Ù† Ùˆ Ø¨Ø§ ÙØ§ØµÙ„Ù‡ Ù…Ø¹Ù…ÙˆÙ„ÛŒ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ù†.

Ù…Ø­ØªÙˆØ§ Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³:
"""

    # Introduction prompt
    INTRO_PROMPT_TEMPLATE = """
**Ù†Ù‚Ø´ Ø´Ù…Ø§:** 
Ù…ØªØ®ØµØµ ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ÛŒ SEO Ø¨Ø±Ø§ÛŒ ÙˆØ¨â€ŒØ³Ø§ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ.

**ÙˆØ±ÙˆØ¯ÛŒâ€ŒÙ‡Ø§:**
- **Ù†Ø§Ù… ÙˆØ¨â€ŒØ³Ø§ÛŒØª:** {project_name}
- **Ù…ÙˆØ¶ÙˆØ¹ Ù…Ù‚Ø§Ù„Ù‡:** {main_topic}
- **Ù‡Ø¯ÛŒÙ†Ú¯â€ŒÙ‡Ø§ÛŒ Ù…Ù‚Ø§Ù„Ù‡:** {all_headings}
- **Ø®Ù„Ø§ØµÙ‡ Ù…Ø­ØªÙˆØ§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡:** {content_summary}

**Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„:**
ÛŒÚ© Ù…Ù‚Ø¯Ù…Ù‡ Ø¬Ø°Ø§Ø¨ Ùˆ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ù…Ù‚Ø§Ù„Ù‡ Ø¨Ù†ÙˆÛŒØ³.

**Ø§Ù„Ø²Ø§Ù…Ø§Øª:**
- Ø·ÙˆÙ„: 150-200 Ú©Ù„Ù…Ù‡
- Ø¬Ø°Ø¨ Ø®ÙˆØ§Ù†Ù†Ø¯Ù‡ Ø§Ø² Ù‡Ù…Ø§Ù† Ø§Ø¨ØªØ¯Ø§
- Ù…Ø¹Ø±ÙÛŒ Ù…ÙˆØ¶ÙˆØ¹ Ùˆ Ø§Ù‡Ù…ÛŒØª Ø¢Ù†
- Ø§Ø´Ø§Ø±Ù‡ Ø¨Ù‡ Ø¢Ù†Ú†Ù‡ Ø¯Ø± Ù…Ù‚Ø§Ù„Ù‡ Ø®ÙˆØ§Ù‡Ø¯ Ø¢Ù…Ø¯
- Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ SEO Ø¨Ø§ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø§ØµÙ„ÛŒ

**Ø®Ø±ÙˆØ¬ÛŒ:**
ÙÙ‚Ø· Ù…ØªÙ† Ù…Ù‚Ø¯Ù…Ù‡ Ø¨Ø§ ÙØ±Ù…Øª HTML (Ø¨Ø¯ÙˆÙ† ØªÚ¯ <h2>ØŒ ÙÙ‚Ø· <p> Ùˆ <strong>).
"""

    # Conclusion prompt  
    CONCLUSION_PROMPT_TEMPLATE = """
**Ù†Ù‚Ø´ Ø´Ù…Ø§:** 
Ù…ØªØ®ØµØµ ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ÛŒ SEO Ø¨Ø±Ø§ÛŒ ÙˆØ¨â€ŒØ³Ø§ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ.

**ÙˆØ±ÙˆØ¯ÛŒâ€ŒÙ‡Ø§:**
- **Ù†Ø§Ù… ÙˆØ¨â€ŒØ³Ø§ÛŒØª:** {project_name}
- **Ù…ÙˆØ¶ÙˆØ¹ Ù…Ù‚Ø§Ù„Ù‡:** {main_topic}
- **Ù‡Ø¯ÛŒÙ†Ú¯â€ŒÙ‡Ø§ÛŒ Ù…Ù‚Ø§Ù„Ù‡:** {all_headings}
- **Ø®Ù„Ø§ØµÙ‡ Ù…Ø­ØªÙˆØ§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡:** {content_summary}

**Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„:**
ÛŒÚ© Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ù‚ÙˆÛŒ Ùˆ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ù…Ù‚Ø§Ù„Ù‡ Ø¨Ù†ÙˆÛŒØ³.

**Ø§Ù„Ø²Ø§Ù…Ø§Øª:**
- Ø·ÙˆÙ„: 100-150 Ú©Ù„Ù…Ù‡
- Ø¬Ù…Ø¹â€ŒØ¨Ù†Ø¯ÛŒ Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ
- Ø§Ø±Ø§Ø¦Ù‡ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ
- Ø¯Ø¹ÙˆØª Ø¨Ù‡ Ø§Ù‚Ø¯Ø§Ù… (CTA) Ø¯Ø± ØµÙˆØ±Øª Ù…Ù†Ø§Ø³Ø¨ Ø¨ÙˆØ¯Ù†
- Ø®Ø§ØªÙ…Ù‡ Ù‚ÙˆÛŒ Ùˆ Ø¨Ù‡ ÛŒØ§Ø¯Ù…Ø§Ù†Ø¯Ù†ÛŒ

**Ø®Ø±ÙˆØ¬ÛŒ:**
ÙÙ‚Ø· Ù…ØªÙ† Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ø¨Ø§ ÙØ±Ù…Øª HTML (Ø¨Ø¯ÙˆÙ† ØªÚ¯ <h2>ØŒ ÙÙ‚Ø· <p> Ùˆ <strong>).
"""
    
    def __init__(self, config: Dict):
        """
        Initialize Content Generator.
        
        Args:
            config: Configuration dictionary
        """
        self.config = config
        logger.info("âœ… Content Generator initialized")
    
    def read_excel_with_headers(self, excel_path: str) -> pd.DataFrame:
        """
        Read Excel file with proper header detection.
        
        Args:
            excel_path: Path to Excel file
            
        Returns:
            DataFrame with headers from first row
        """
        try:
            # Read with first row as header
            df = pd.read_excel(excel_path, header=0)
            logger.info(f"ğŸ“Š Read {len(df)} rows from {Path(excel_path).name}")
            logger.info(f"ğŸ“‹ Columns: {list(df.columns)}")
            return df
            
        except Exception as e:
            logger.error(f"Failed to read Excel file: {e}")
            raise
    
    def extract_topic_and_headings(self, row: pd.Series) -> Tuple[str, List[str]]:
        """
        Extract main topic and headings from a row.
        
        Args:
            row: DataFrame row
            
        Returns:
            Tuple of (main_topic, list of headings)
        """
        # First column is main topic
        main_topic = str(row.iloc[0]) if pd.notna(row.iloc[0]) else ""
        
        # Find heading columns (columns that start with "Ù‡Ø¯ÛŒÙ†Ú¯ H2")
        headings = []
        for i in range(len(row)):
            column_name = str(row.index[i])
            value = row.iloc[i]
            
            # Check if this is a heading column
            if "Ù‡Ø¯ÛŒÙ†Ú¯ H2" in column_name and pd.notna(value) and str(value).strip():
                headings.append(str(value).strip())
        
        return main_topic, headings
    
    def generate_heading_content(
        self,
        project_name: str,
        main_topic: str,
        current_heading: str,
        related_headings: List[str],
        word_count: int,
        ai_client: Any,
        model_name: str,
        provider: str,
        content_instructions: str = ""
    ) -> str:
        """
        Generate content for a single heading.
        
        Args:
            project_name: Project/website name
            main_topic: Main topic of article
            current_heading: Current heading to generate content for
            related_headings: Other headings in article
            word_count: Target word count
            ai_client: AI client instance
            model_name: Model name
            provider: Provider type
            content_instructions: Additional instructions for content generation
            
        Returns:
            Generated HTML content
        """
        # Format related headings
        related_text = "\n".join([f"  - {h}" for h in related_headings if h != current_heading])
        
        # Build prompt
        prompt = self.HEADING_PROMPT_TEMPLATE.format(
            project_name=project_name,
            main_topic=main_topic,
            current_heading=current_heading,
            related_headings=related_text,
            word_count=word_count
        )
        
        # Add content instructions if provided
        if content_instructions:
            prompt += f"\n\n**Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ Ø§Ø¶Ø§ÙÛŒ:**\n{content_instructions}\n\n"
        
        logger.info(f"  ğŸ¤– Generating content for: {current_heading[:50]}... ({word_count} words)")
        
        try:
            # Generate content based on provider
            if provider in ["openai", "openai_compatible", "grok"]:
                response = ai_client.chat.completions.create(
                    model=model_name,
                    messages=[
                        {"role": "system", "content": "You are an expert Persian SEO content writer."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.7,
                    max_tokens=4000
                )
                content = response.choices[0].message.content.strip()
                
            elif provider == "anthropic":
                response = ai_client.messages.create(
                    model=model_name,
                    max_tokens=4000,
                    temperature=0.7,
                    messages=[{"role": "user", "content": prompt}]
                )
                content = response.content[0].text.strip()
            
            else:
                raise ValueError(f"Unsupported provider: {provider}")
            
            return content
            
        except Exception as e:
            logger.error(f"  âŒ Failed to generate content: {e}")
            raise
    
    def generate_introduction(
        self,
        project_name: str,
        main_topic: str,
        all_headings: List[str],
        content_summary: str,
        ai_client: Any,
        model_name: str,
        provider: str
    ) -> str:
        """Generate introduction for article."""
        headings_text = "\n".join([f"  - {h}" for h in all_headings])
        
        prompt = self.INTRO_PROMPT_TEMPLATE.format(
            project_name=project_name,
            main_topic=main_topic,
            all_headings=headings_text,
            content_summary=content_summary
        )
        
        logger.info(f"  ğŸ“ Generating introduction...")
        
        try:
            if provider in ["openai", "openai_compatible", "grok"]:
                response = ai_client.chat.completions.create(
                    model=model_name,
                    messages=[
                        {"role": "system", "content": "You are an expert Persian SEO content writer."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.7,
                    max_tokens=1000
                )
                return response.choices[0].message.content.strip()
                
            elif provider == "anthropic":
                response = ai_client.messages.create(
                    model=model_name,
                    max_tokens=1000,
                    temperature=0.7,
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.content[0].text.strip()
                
        except Exception as e:
            logger.error(f"  âŒ Failed to generate introduction: {e}")
            raise
    
    def generate_conclusion(
        self,
        project_name: str,
        main_topic: str,
        all_headings: List[str],
        content_summary: str,
        ai_client: Any,
        model_name: str,
        provider: str
    ) -> str:
        """Generate conclusion for article."""
        headings_text = "\n".join([f"  - {h}" for h in all_headings])
        
        prompt = self.CONCLUSION_PROMPT_TEMPLATE.format(
            project_name=project_name,
            main_topic=main_topic,
            all_headings=headings_text,
            content_summary=content_summary
        )
        
        logger.info(f"  ğŸ“ Generating conclusion...")
        
        try:
            if provider in ["openai", "openai_compatible", "grok"]:
                response = ai_client.chat.completions.create(
                    model=model_name,
                    messages=[
                        {"role": "system", "content": "You are an expert Persian SEO content writer."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.7,
                    max_tokens=800
                )
                return response.choices[0].message.content.strip()
                
            elif provider == "anthropic":
                response = ai_client.messages.create(
                    model=model_name,
                    max_tokens=800,
                    temperature=0.7,
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.content[0].text.strip()
                
        except Exception as e:
            logger.error(f"  âŒ Failed to generate conclusion: {e}")
            raise
    
    def ensure_content_harmony(
        self,
        heading_contents: List[str],
        headings: List[str],
        main_topic: str,
        ai_client: Any,
        model_name: str,
        provider: str
    ) -> List[str]:
        """
        Check and ensure content harmony across all headings.
        
        Args:
            heading_contents: List of generated content for each heading
            headings: List of headings
            main_topic: Main topic
            ai_client: AI client instance
            model_name: Model name
            provider: Provider type
            
        Returns:
            List of harmonized content
        """
        # Build harmony check prompt
        content_preview = ""
        for i, (heading, content) in enumerate(zip(headings, heading_contents), 1):
            # Get first 150 chars of content for preview
            text_only = re.sub(r'<[^>]+>', '', content)
            preview = text_only[:150] + "..." if len(text_only) > 150 else text_only
            content_preview += f"{i}. **{heading}**: {preview}\n"
        
        harmony_prompt = f"""
**Ù†Ù‚Ø´ Ø´Ù…Ø§:** 
Ù…ØªØ®ØµØµ ÙˆÛŒØ±Ø§ÛŒØ´ Ùˆ Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ù…Ø§Ù‡Ù†Ú¯ÛŒ Ù…Ø­ØªÙˆØ§.

**Ù…ÙˆØ¶ÙˆØ¹ Ù…Ù‚Ø§Ù„Ù‡:** {main_topic}

**Ù…Ø­ØªÙˆØ§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡:**
{content_preview}

**Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„:**
Ø§ÛŒÙ† Ù…Ø­ØªÙˆØ§ Ø±Ø§ Ø§Ø² Ù†Ø¸Ø± Ù‡Ù…Ø§Ù‡Ù†Ú¯ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†. Ø¢ÛŒØ§:
1. Ù„Ø­Ù† Ù†ÙˆØ´ØªØ§Ø±ÛŒ Ø¯Ø± Ù‡Ù…Ù‡ Ø¨Ø®Ø´â€ŒÙ‡Ø§ ÛŒÚ©Ø³Ø§Ù† Ø§Ø³ØªØŸ
2. Ø³Ø¨Ú© Ù†Ú¯Ø§Ø±Ø´ Ø«Ø§Ø¨Øª Ø§Ø³ØªØŸ
3. Ø§Ø±ØªØ¨Ø§Ø· Ù…Ù†Ø·Ù‚ÛŒ Ø¨ÛŒÙ† Ø¨Ø®Ø´â€ŒÙ‡Ø§ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŸ
4. ØªÚ©Ø±Ø§Ø± ØºÛŒØ±Ø¶Ø±ÙˆØ±ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù†ÛŒØ³ØªØŸ

**Ø®Ø±ÙˆØ¬ÛŒ:**
ÙÙ‚Ø· "OK" Ø¨Ù†ÙˆÛŒØ³ Ø§Ú¯Ø± Ù…Ø­ØªÙˆØ§ Ù‡Ù…Ø§Ù‡Ù†Ú¯ Ø§Ø³Øª.
Ø§Ú¯Ø± Ù…Ø´Ú©Ù„ÛŒ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŒ Ø´Ù…Ø§Ø±Ù‡ Ø¨Ø®Ø´ Ùˆ ØªÙˆØ¶ÛŒØ­ Ú©ÙˆØªØ§Ù‡ Ø¨Ø¯Ù‡ (Ù…Ø«Ø§Ù„: "Ø¨Ø®Ø´ 2: Ù„Ø­Ù† Ø®ÛŒÙ„ÛŒ Ø±Ø³Ù…ÛŒâ€ŒØªØ± Ø§Ø² Ø¨Ù‚ÛŒÙ‡ Ø§Ø³Øª").
"""
        
        try:
            if provider in ["openai", "openai_compatible", "grok"]:
                response = ai_client.chat.completions.create(
                    model=model_name,
                    messages=[
                        {"role": "system", "content": "You are a content harmony expert."},
                        {"role": "user", "content": harmony_prompt}
                    ],
                    temperature=0.3,
                    max_tokens=500
                )
                result = response.choices[0].message.content.strip()
            
            elif provider == "anthropic":
                response = ai_client.messages.create(
                    model=model_name,
                    max_tokens=500,
                    temperature=0.3,
                    messages=[
                        {"role": "user", "content": harmony_prompt}
                    ]
                )
                result = response.content[0].text.strip()
            
            elif provider == "gemini":
                response = ai_client.generate_content(
                    harmony_prompt,
                    generation_config={
                        'temperature': 0.3,
                        'max_output_tokens': 500
                    }
                )
                result = response.text.strip()
            
            else:
                logger.warning(f"Unknown provider: {provider}")
                return heading_contents
            
            # Log harmony check result
            if result.upper() == "OK":
                logger.info("âœ… Content harmony confirmed")
            else:
                logger.warning(f"âš ï¸ Harmony note: {result}")
            
            return heading_contents
            
        except Exception as e:
            logger.error(f"Harmony check failed: {e}")
            return heading_contents
    
    def generate_article_interactive(
        self,
        row_index: int,
        main_topic: str,
        headings: List[str],
        project_name: str,
        ai_model,
        total_rows: int,
        content_instructions: str = ""
    ) -> Dict[str, Any]:
        """
        Generate complete article interactively for one row.
        
        Args:
            row_index: Current row index (0-based)
            main_topic: Main topic from first column
            headings: List of headings
            project_name: Project name
            ai_model: AI model to use
            total_rows: Total number of rows
            content_instructions: Additional instructions for content generation
            
        Returns:
            Dictionary with article data
        """
        print(f"\n{'='*70}")
        print(f"ğŸ“ Article {row_index + 1} of {total_rows}")
        print(f"{'='*70}")
        print(f"\nğŸ“Œ Topic: {main_topic}")
        print(f"\nğŸ“‹ Headings ({len(headings)}):")
        for i, h in enumerate(headings, 1):
            print(f"   {i}. {h}")
        
        # Confirm
        print(f"\n{'-'*70}")
        confirm = input(f"Generate content for this article? (Y/n): ").strip().lower()
        if confirm in ['n', 'no']:
            print("â­ï¸  Skipped")
            return None
        
        # Get total word count
        while True:
            try:
                total_words_input = input(f"\nEnter total word count for entire article (e.g., 1500): ").strip()
                total_words = int(total_words_input)
                if total_words < 100:
                    print("âŒ Minimum 100 words required")
                    continue
                break
            except ValueError:
                print("âŒ Please enter a valid number")
        
        print(f"âœ… Total: {total_words} words")
        
        # Get word count for each heading
        heading_word_counts = []
        remaining_words = total_words
        
        print(f"\n{'='*70}")
        print(f"ğŸ“Š Word Distribution (Total: {total_words} words)")
        print(f"{'='*70}")
        
        for i, heading in enumerate(headings):
            print(f"\n[{i+1}/{len(headings)}] {heading}")
            print(f"   Remaining: {remaining_words} words")
            
            while True:
                try:
                    suggestion = remaining_words // (len(headings) - i)
                    word_input = input(f"   Word count (suggested: {suggestion}): ").strip()
                    
                    if not word_input:
                        word_count = suggestion
                    else:
                        word_count = int(word_input)
                    
                    if word_count > remaining_words:
                        print(f"   âŒ Exceeds remaining words ({remaining_words})")
                        continue
                    
                    if word_count < 50:
                        print(f"   âŒ Minimum 50 words per heading")
                        continue
                    
                    heading_word_counts.append(word_count)
                    remaining_words -= word_count
                    print(f"   âœ… Allocated: {word_count} words")
                    break
                    
                except ValueError:
                    print("   âŒ Invalid number")
        
        # Generate content for each heading
        ai_client = ai_model.get_client()
        heading_contents = []
        
        print(f"\n{'='*70}")
        print(f"ğŸš€ Generating Content")
        print(f"{'='*70}\n")
        
        for i, (heading, word_count) in enumerate(zip(headings, heading_word_counts)):
            content = self.generate_heading_content(
                project_name=project_name,
                main_topic=main_topic,
                current_heading=heading,
                related_headings=headings,
                word_count=word_count,
                ai_client=ai_client,
                model_name=ai_model.config.get('model', ''),
                provider=ai_model.provider,
                content_instructions=content_instructions
            )
            heading_contents.append(content)
            print(f"  âœ… [{i+1}/{len(headings)}] {heading[:40]}...")
        
        # Generate introduction
        content_summary = f"Ø§ÛŒÙ† Ù…Ù‚Ø§Ù„Ù‡ Ø´Ø§Ù…Ù„ {len(headings)} Ø¨Ø®Ø´ Ø§Ø³Øª: " + "ØŒ ".join(headings[:3])
        if len(headings) > 3:
            content_summary += f" Ùˆ {len(headings) - 3} Ø¨Ø®Ø´ Ø¯ÛŒÚ¯Ø±"
        
        intro = self.generate_introduction(
            project_name=project_name,
            main_topic=main_topic,
            all_headings=headings,
            content_summary=content_summary,
            ai_client=ai_client,
            model_name=ai_model.config.get('model', ''),
            provider=ai_model.provider
        )
        print(f"  âœ… Introduction generated")
        
        # Generate conclusion
        conclusion = self.generate_conclusion(
            project_name=project_name,
            main_topic=main_topic,
            all_headings=headings,
            content_summary=content_summary,
            ai_client=ai_client,
            model_name=ai_model.config.get('model', ''),
            provider=ai_model.provider
        )
        print(f"  âœ… Conclusion generated")
        
        # Ensure content harmony
        print(f"\n  ğŸ” Checking content harmony...")
        heading_contents = self.ensure_content_harmony(
            heading_contents=heading_contents,
            headings=headings,
            main_topic=main_topic,
            ai_client=ai_client,
            model_name=ai_model.config.get('model', ''),
            provider=ai_model.provider
        )
        print(f"  âœ… Content harmony verified")
        
        # Combine all content
        full_content = f"{intro}\n\n"
        
        for heading, content in zip(headings, heading_contents):
            full_content += f"<h2>{heading}</h2>\n{content}\n\n"
        
        full_content += f"<h2>Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ</h2>\n{conclusion}"
        
        # Generate SEO title and meta
        seo_title = main_topic[:60] if len(main_topic) <= 60 else main_topic[:57] + "..."
        meta_desc = f"{main_topic} - Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ú©Ø§Ù…Ù„"[:160]
        
        result = {
            'main_topic': main_topic,
            'headings': headings,
            'seo_title': seo_title,
            'meta_description': meta_desc,
            'full_content': full_content,
            'word_count': sum(heading_word_counts) + 350  # approximate with intro/conclusion
        }
        
        print(f"\nâœ… Article completed: ~{result['word_count']} words\n")
        
        return result
