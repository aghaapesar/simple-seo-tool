# SEO Content Analysis & Optimization Tool v2.3.2

A powerful, interactive Python application optimized for **Persian/Farsi content** that helps you improve your website's SEO through:
1. **Content Optimization**: Analyze Google Search Console data with Persian-aware AI
2. **SEO Data Collection**: Scrape and audit page titles, meta descriptions, and SEO tags
3. **AI Content Generation** âœ¨ NEW: Generate SEO-optimized content with multi-model AI support
4. **Internal Linking**: Smart internal linking with semantic analysis
5. **Knowledge Base**: Track content history and avoid duplicates

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Persian Optimized](https://img.shields.io/badge/Persian-Optimized-green.svg)]()
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## ğŸ†• What's New in v2.3.2

### ğŸ”§ Advanced Internal Linking (Latest)
- âœ… **Smart Product Name Linking**: Priority for 2-3 syllable product names (Ø¨Ø°Ø± Ù¾ÛŒØ§Ø²ØŒ Ú©Ø§Ø´Øª Ú¯Ù„)
- âœ… **Semantic Anchor Text**: Intelligent selection of anchor text based on product relevance
- âœ… **Even Link Distribution**: Links spread evenly across content, not just beginning/end
- âœ… **Enhanced Word Export**: Fixed Word document creation with better error handling
- âœ… **Persian Product Recognition**: 50+ Persian product words with syllable-based matching

### ğŸ”§ Bug Fixes & Improvements (v2.3.1)
- âœ… **Enhanced Internal Linking**: Improved semantic matching with Persian word relationships
- âœ… **Fixed Word Export**: Resolved python-docx dependency issue
- âœ… **Better Link Relevance**: More accurate content-to-URL matching
- âœ… **Dynamic Version Management**: Automatic version reading from VERSION file

---

## ğŸ†• What's New in v2.3.0

### AI Content Generation âœ¨ NEW
- âœ… **Multi-Model AI Support**: Choose from OpenAI, Claude, Gemini, Grok, and more
- âœ… **Persian SEO Content**: Specialized prompts for natural, SEO-optimized Persian content
- âœ… **Smart Internal Linking**: Automatic internal links based on sitemap analysis
- âœ… **Multiple Export Formats**: Excel, Word (.docx), and editor-ready HTML
- âœ… **Model Selection**: Pick different AI models for different operations
- âœ… **Connection Testing**: Test all AI models before use

### Multi-Model AI Configuration
- âœ… **Configure Multiple Models**: Set up multiple AI providers in one config file
- âœ… **Default Model**: Set a default model for all operations
- âœ… **Per-Operation Selection**: Choose specific models for specific tasks
- âœ… **Supported Providers**: OpenAI, Claude (Anthropic), Gemini (Google), Grok, and OpenAI-compatible APIs

### Internal Linking System
- âœ… **Semantic Matching**: Links based on content relevance
- âœ… **Smart Rules**: 1 link per 300-400 words, no links in headings
- âœ… **Priority System**: Categories > Products > Blog posts
- âœ… **Anchor Text Optimization**: Natural anchor text with 5-syllable limit

## ğŸ†• What's New in v2.2.3

### Persian Language Optimization ğŸ‡®ğŸ‡· (Enhanced)
- âœ… **Persian-Aware AI Prompts**: Specialized prompts for Farsi content analysis
- âœ… **LSI Keywords**: Persian-specific related keywords suggestions
- âœ… **Search Intent**: Understanding Iranian user behavior and intent
- âœ… **Content Structure**: H2/H3 headings optimized for Persian SEO
- âœ… **Persian URL Decoding**: Proper handling of Persian URLs in scraping mode
- âœ… **Fully Persian Excel Output**: All column headers and content in Persian

### Smart Clustering & Fallback Strategy ğŸ”„
- âœ… **Intelligent Duplicate Detection**: Prevents repetitive content with adjustable thresholds
- âœ… **Fallback Clustering**: Multiple retry strategies when clustering fails
- âœ… **User-Guided Recovery**: Interactive options to adjust clustering parameters
- âœ… **Test Mode Support**: Clustering works in test mode with limited data
- âœ… **Threshold Adjustment**: Lower duplicate detection threshold on demand

### Knowledge Base System ğŸ§ 
- âœ… **Project Memory**: Track content history for each project
- âœ… **Duplicate Detection**: Automatically detect similar content to avoid repetition
- âœ… **Performance Tracking**: Compare predicted vs actual metrics
- âœ… **Smart Suggestions**: Learn from past performance to improve predictions

### Previous Features (v2.0)
- âœ… **Interactive Mode**: User-friendly prompts and selections
- âœ… **Dual Modes**: Content optimization + SEO data collection
- âœ… **Smart Sitemap Management**: Automatic caching, retry logic, selective downloads
- âœ… **Multi-File Support**: Process multiple Excel files in one run
- âœ… **Test Mode**: Quick validation with 10-item limits
- âœ… **Resume Capability**: Continue interrupted scraping sessions
- âœ… **Progress Tracking**: Real-time progress bars and status messages
- âœ… **Organized Structure**: Separate folders for input, output, and sitemaps

---

## ğŸ“‹ Table of Contents

- [English Documentation](#english-documentation)
  - [Quick Start](#quick-start)
  - [Features](#features)
  - [Installation](#installation)
  - [Usage](#usage)
  - [Mode 1: Content Optimization](#mode-1-content-optimization)
  - [Mode 2: SEO Data Collection](#mode-2-seo-data-collection)
  - [Mode 3: AI Content Generation](#mode-3-ai-content-generation-new)
  - [Multi-Model AI Configuration](#multi-model-ai-configuration)
  - [Troubleshooting](#troubleshooting)
- [Ù…Ø³ØªÙ†Ø¯Ø§Øª ÙØ§Ø±Ø³ÛŒ](#Ù…Ø³ØªÙ†Ø¯Ø§Øª-ÙØ§Ø±Ø³ÛŒ)
  - [Ø´Ø±ÙˆØ¹ Ø³Ø±ÛŒØ¹](#Ø´Ø±ÙˆØ¹-Ø³Ø±ÛŒØ¹)
  - [ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§](#ÙˆÛŒÚ˜Ú¯ÛŒÙ‡Ø§)
  - [Ù†ØµØ¨](#Ù†ØµØ¨)
  - [Ø§Ø³ØªÙØ§Ø¯Ù‡](#Ø§Ø³ØªÙØ§Ø¯Ù‡)
  - [Ø­Ø§Ù„Øª Û±: Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø­ØªÙˆØ§](#Ø­Ø§Ù„Øª-Û±-Ø¨Ù‡ÛŒÙ†Ù‡Ø³Ø§Ø²ÛŒ-Ù…Ø­ØªÙˆØ§-ÙØ§Ø±Ø³ÛŒ-Ø¨Ù‡ÛŒÙ†Ù‡Ø´Ø¯Ù‡-)
  - [Ø­Ø§Ù„Øª Û²: Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ SEO](#Ø­Ø§Ù„Øª-Û²-Ø¬Ù…Ø¹Ø¢ÙˆØ±ÛŒ-Ø¯Ø§Ø¯Ù‡Ù‡Ø§ÛŒ-seo)
  - [Ø­Ø§Ù„Øª Û³: ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯](#Ø­Ø§Ù„Øª-Û³-ØªÙˆÙ„ÛŒØ¯-Ù…Ø­ØªÙˆØ§ÛŒ-Ù‡ÙˆØ´Ù…Ù†Ø¯-Ø¬Ø¯ÛŒØ¯)
  - [Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ú†Ù†Ø¯ Ù…Ø¯Ù„ AI](#Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ-Ú†Ù†Ø¯-Ù…Ø¯Ù„-ai)
  - [Ø±ÙØ¹ Ù…Ø´Ú©Ù„Ø§Øª](#Ø±ÙØ¹-Ù…Ø´Ú©Ù„Ø§Øª)

---

# English Documentation

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Configure API
Edit `config.yaml` with your AI provider credentials:
```yaml
ai:
  provider: openai_compatible
  model: openai/gpt-4o-mini
  compatible_base_url: "https://ai.liara.ir/api/YOUR_PROJECT_ID/v1"
  compatible_api_key: "YOUR_API_KEY"
```

### 3. Prepare Your Data
- Copy Excel files from Google Search Console to `input/` folder
- Have your sitemap URL ready

### 4. Run the Tool
```bash
# Interactive mode (recommended for first time)
python3 main.py

# Content optimization mode directly
python3 main.py --mode content

# SEO data collection mode
python3 main.py --mode scraping

# AI Content Generation mode âœ¨ NEW
python3 main.py --mode generation

# Test mode (10 items only)
python3 main.py --mode content --test
```

---

## ğŸ¯ Features

### Mode 1: Content Optimization (Persian-Optimized)
Analyze existing content and find new opportunities
- **Search Console Analysis**: Load and analyze Google Search Console exports
- **Persian-Aware AI**: Specialized analysis for Farsi content and Iranian users
- **LSI Keywords**: Persian-specific related keywords (Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· ÙØ§Ø±Ø³ÛŒ)
- **Search Intent Analysis**: Understanding Iranian user search behavior
- **Comprehensive Suggestions**: 
  - Content improvements with Persian SEO best practices
  - H2/H3 headings optimized for Farsi queries
  - Meta descriptions (Ø­Ø¯Ø§Ú©Ø«Ø± Û±Û¶Û° Ú©Ø§Ø±Ø§Ú©ØªØ±)
  - FAQ suggestions based on Persian search patterns
  - Internal linking with Persian anchor texts
- **Knowledge Base Integration**: 
  - Track all generated content
  - Avoid duplicate topics automatically
  - Learn from performance over time

### Mode 2: SEO Data Collection
- **Page Scraping**: Extract titles, meta descriptions, H1s from all pages
- **Batch Processing**: Scrape pages in controlled batches with pause/resume
- **Progress Tracking**: Real-time progress bars and statistics
- **Error Handling**: Automatic retry logic and graceful error management
- **Resume Capability**: Pick up where you left off if interrupted

### Common Features
- **Interactive Sitemap Management**:
  - Automatic caching (no re-downloads)
  - 10-retry logic with exponential backoff
  - Sitemap index support with selective downloads
  - User prompts for manual retry
  
- **Smart File Handling**:
  - Multi-file selection from `input/` directory
  - File metadata display (size, date)
  - Automatic backup creation
  
- **Test Mode**: Validate with 10-item limits before full run
- **Comprehensive Logging**: Detailed logs saved to `seo_optimizer.log`
- **Multiple AI Providers**: OpenAI, Azure, Anthropic, or compatible APIs

---

## ğŸ“¦ Installation

### Prerequisites
- Python 3.8 or higher
- pip (Python package manager)
- Internet connection for AI API calls

### Setup
```bash
# Create project directory
cd SEOContentAnalysis

# Install dependencies
pip install -r requirements.txt

# Create config from sample
cp config.sample.yaml config.yaml

# Edit config.yaml with your credentials
nano config.yaml
```

### Directory Structure
```
SEOContentAnalysis/
â”œâ”€â”€ input/              # Place your Excel files here
â”œâ”€â”€ sitemaps/           # Downloaded sitemaps (auto-cached)
â”œâ”€â”€ output/             # Generated Excel reports
â”œâ”€â”€ logs/               # Application logs
â”œâ”€â”€ knowledge_base/     # Project memory & content history âœ¨ NEW
â”œâ”€â”€ main.py             # Main application
â”œâ”€â”€ config.yaml         # Your configuration
â””â”€â”€ src/                # Source modules
    â”œâ”€â”€ knowledge_base.py  # Knowledge base system âœ¨ NEW
    â””â”€â”€ ...
```

---

## ğŸ® Usage

### Mode 1: Content Optimization

**Purpose**: Analyze Search Console data to improve existing content and find new opportunities.

**Workflow**:
1. Export data from Google Search Console (Performance â†’ Export)
2. Copy Excel file(s) to `input/` folder
3. Run: `python3 main.py --mode content`
4. **Enter project name** (e.g., example.com) - used for knowledge base âœ¨
5. Select files when prompted
6. Enter sitemap URL when requested
7. Wait for Persian-optimized AI analysis to complete
8. Review results in `output/` folder

**What Happens Behind the Scenes**:
- AI analyzes with Persian language understanding
- Knowledge base checks for duplicate content
- Suggestions include Persian LSI keywords
- Content structure optimized for Iranian users
- All generated content tracked for future reference

**Output Files**:
- `improvements_[filename].xlsx` - Suggestions for existing pages
- `new_content_[filename].xlsx` - Ideas for new articles

**Example**:
```bash
$ python3 main.py --mode content

ğŸš€ SEO CONTENT ANALYSIS & OPTIMIZATION TOOL
============================================
Version: 2.1 | Persian AI + Knowledge Base

ğŸ“‹ PROJECT IDENTIFICATION
Enter a name for this project: example.com
âœ… Project name: example.com

ğŸ“Š FOUND 2 EXCEL FILE(S)
  [1] example-blog.xlsx (94.5 KB | 2025-10-11)
  [2] example-product.xlsx (102.1 KB | 2025-10-11)

Your selection: 1,2

ğŸ—ºï¸  SITEMAP CONFIGURATION
Enter your sitemap URL: https://example.com/sitemap.xml

[Processing with Persian-optimized AI...]

âœ… Knowledge base: No duplicate content found
âœ… Generated 15 improvement suggestions
âœ… Created 8 new content ideas with Persian structure
```

---

### Mode 2: SEO Data Collection

**Purpose**: Scrape and audit all pages in your sitemap for SEO data.

**Workflow**:
1. Run: `python3 main.py --mode scraping`
2. Enter sitemap URL when prompted
3. Choose batch size (e.g., 50 pages at a time)
4. Review each batch, continue or pause
5. Results saved to `output/seo_data_[domain].xlsx`

**Collected Data**:
- Page URL
- Title tag
- Meta description
- H1 heading
- Canonical URL
- Open Graph tags (title, description)
- Twitter Card tags

**Example**:
```bash
$ python3 main.py --mode scraping --test

ğŸ” MODE: SEO Data Collection
ğŸ§ª TEST MODE: Will scrape only 10 pages

Enter sitemap URL: https://example.com/sitemap.xml

ğŸ“¥ Downloading sitemap...
âœ… Extracted 1,250 URLs

How many pages per batch? 10

ğŸ”„ Scraping batch: 1 to 10 of 10
Scraping pages: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10

âœ… SCRAPING COMPLETED!
ğŸ“ Output: output/seo_data_example.com.xlsx
```

---

### Mode 3: AI Content Generation âœ¨ NEW

**Purpose**: Generate SEO-optimized Persian content with AI using multiple models and automatic internal linking.

**Workflow**:
1. Run: `python3 main.py --mode generation`
2. System tests all configured AI models
3. Choose to use default model or select per operation
4. **Select Excel file from `output/` folder** (files generated from Mode 1)
5. Enter project name
6. Select AI model for content generation
7. **For each article row**:
   - System shows topic from first column
   - Shows all headings from other columns
   - Ask for confirmation
   - Ask for total word count for entire article
   - Ask for word count per heading
   - Generate content for each heading
   - Generate introduction and conclusion
   - Combine into complete article
8. Optionally add internal links based on sitemap
9. Export to Word and HTML formats

**Note**: 
- Excel files are read from the `output/` folder (files generated by Mode 1)
- First row is treated as headers
- **Column 1**: Article topic (automatically used)
- **Columns 2-6**: Additional data (predictions, clusters, content type, search intent, word count)
- **Columns 7+**: H2 headings (only these are used for content generation)
- Each row represents one complete article

**Excel Structure Example**:
| Ø¹Ù†ÙˆØ§Ù† Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ù…Ù‚Ø§Ù„Ù‡ | Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†Ù…Ø§ÛŒØ´ | Ú©Ù„Ø§Ø³ØªØ± Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡ | Ù†ÙˆØ¹ Ù…Ø­ØªÙˆØ§ | Ù‡Ø¯Ù Ø¬Ø³ØªØ¬Ùˆ | ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„Ù…Ø§Øª | Ù‡Ø¯ÛŒÙ†Ú¯ H2 Ø´Ù…Ø§Ø±Ù‡ 1 | Ù‡Ø¯ÛŒÙ†Ú¯ H2 Ø´Ù…Ø§Ø±Ù‡ 2 | ... |
|---------------------|-------------|-------------|---------|---------|-----------|-----------------|-----------------|-----|
| Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ú©Ø§Ø´Øª Ú¯Ù„Ù‡Ø§ | 1500 | Ú©Ø§Ø´Øª | Ø±Ø§Ù‡Ù†Ù…Ø§ | Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ | 2000 | Ù…Ø¹Ø±ÙÛŒ Ú¯Ù„ Ù„ÛŒÙ„ÛŒÙˆÙ… | Ù†Ø­ÙˆÙ‡ Ú©Ø§Ø´Øª | ... |

**Key Features**:
- **Multi-Model AI Support**: Choose from OpenAI, Claude, Gemini, Grok, and more
- **Persian SEO Optimization**: Content follows Persian SEO best practices
- **Smart Internal Linking**: 
  - 1 link per 300-400 words
  - No links in headings
  - Priority: Categories > Products > Blog posts
  - Semantic anchor text matching (max 5 syllables)
- **Multiple Export Formats**:
  - Excel: With SEO title, meta description, and content
  - Word: Formatted documents with headings and bold text
  - HTML: Editor-ready (no `<html>`, `<head>`, `<body>` tags)

**Generated Content Includes**:
- SEO-optimized title (max 60 characters)
- Meta description (max 160 characters)
- Full HTML content with proper structure (H2, H3, paragraphs, lists)
- Natural Persian writing with E-E-A-T principles
- Random spacing variations for natural appearance

**Example**:
```bash
$ python3 main.py --mode generation

ğŸš€ SEO CONTENT ANALYSIS & OPTIMIZATION TOOL
============================================
Version: 2.3.0 | Multi-Model AI + Content Generation + Internal Linking

[1/6] AI Model Configuration
======================================================================

ğŸ”Œ Testing AI model connections...
----------------------------------------------------------------------
   Testing liara_gpt4o_mini (openai_compatible)... âœ… Connected
      (Default model)
   Testing claude_sonnet (anthropic)... âœ… Connected
   Testing gemini_pro (gemini)... âœ… Connected
----------------------------------------------------------------------

âœ… 3/3 model(s) connected successfully

ğŸ¤– AI Model Selection
======================================================================

Default model: liara_gpt4o_mini (openai_compatible)

Would you like to use the default model for all operations?
  [Y] Yes, use default for everything
  [N] No, let me choose for each operation

Your choice (Y/n): Y
âœ… Will use liara_gpt4o_mini for all operations

[2/6] Select Input Excel File
======================================================================

ğŸ“Š FOUND 2 EXCEL FILE(S)
  [1] new_content_nazboo-blog.xlsx (45.2 KB | 2025-10-12)
  [2] improvements_nazboo-blog.xlsx (38.7 KB | 2025-10-12)

Your selection: 1
âœ… Selected: new_content_nazboo-blog.xlsx

[3/6] Project Information
======================================================================

ğŸ“‹ PROJECT IDENTIFICATION
Enter a name for this project: nazboo.com
âœ… Project name: nazboo.com

ğŸ“ Enter main topic/theme for content:
   Main topic: Ú©Ø´Ø§ÙˆØ±Ø²ÛŒ Ùˆ Ø¨Ø§ØºØ¨Ø§Ù†ÛŒ

[4/6] Select AI Model for Content Generation
======================================================================
âœ… Using default model: liara_gpt4o_mini

[5/6] Generate Content
======================================================================

ğŸ“ Content Generation Settings
======================================================================

Enter approximate word count per heading: 800
âœ… Target word count: 800 words per heading

ğŸ“Š Found 3 heading column(s):
   - Ø¹Ù†ÙˆØ§Ù† Ø§ØµÙ„ÛŒ
   - H2_1
   - H2_2

Generate content for 15 row(s)? (y/n): y

======================================================================
ğŸš€ Starting Content Generation
======================================================================

Generating content: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15

======================================================================
âœ… Content Generation Complete!
======================================================================
   Total rows: 15
   âœ… Success: 15
   âŒ Failed: 0
   ğŸ“Š Total words generated: 12,340
   ğŸ“ Output: output/content_generated/content_nazboo-blog.xlsx
======================================================================

[6/6] Internal Linking & Export
======================================================================

ğŸ”— Internal Linking
======================================================================

Add internal links to content? (Y/n): y

ğŸ—ºï¸  SITEMAP CONFIGURATION
Enter your sitemap URL: https://nazboo.com/sitemap.xml

ğŸ“¥ Downloading sitemap...
âœ… Extracted 450 URLs

ğŸ“Š URL Statistics:
   - category: 25
   - product: 320
   - blog: 85
   - other: 20

ğŸ”„ Adding internal links...
Adding links: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15

âœ… Internal links added and saved to Excel

======================================================================
ğŸ“„ Export to Word & HTML
======================================================================

Export content to Word and HTML files? (Y/n): y

Exporting files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15

======================================================================
âœ… Export Complete!
======================================================================
   ğŸ“ Word files: 15
   ğŸŒ HTML files: 15
   ğŸ“ Output directory: /path/to/output/documents
======================================================================

======================================================================
ğŸ‰ CONTENT GENERATION COMPLETED!
======================================================================
ğŸ“Š Statistics:
   Total content pieces: 15
   Total words generated: 12,340
   Failed: 0

ğŸ“ Output files:
   Excel: output/content_generated/content_nazboo-blog.xlsx
   Documents: output/documents/
```

**Output Files Structure**:
```
output/
â”œâ”€â”€ content_generated/
â”‚   â””â”€â”€ content_nazboo-blog.xlsx          # Excel with all content
â””â”€â”€ documents/
    â”œâ”€â”€ content_nazboo.com_1_title.docx   # Word documents
    â”œâ”€â”€ content_nazboo.com_1_title.html   # HTML files
    â”œâ”€â”€ content_nazboo.com_2_title.docx
    â”œâ”€â”€ content_nazboo.com_2_title.html
    â””â”€â”€ ...
```

**Excel Output Columns**:
- Original columns from input file
- `SEO_Title`: Optimized title (60 chars)
- `Meta_Description`: Meta description (160 chars)
- `Generated_Content`: Full HTML content with internal links

**Word Document Structure**:
```
SEO Information
---------------
Title: [SEO Title]
Meta Description: [Meta Description]

___________________________________________________________

Content
-------
[Full formatted content with headings, bold text, lists, etc.]
```

**HTML Output** (Editor-Ready):
```html
<!-- SEO Title -->
<!-- Ø¨Ù‡ØªØ±ÛŒÙ† Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø´Øª Ú¯ÙˆØ¬Ù‡ ÙØ±Ù†Ú¯ÛŒ Ø¯Ø± Ø¨Ø§Øº Ø®Ø§Ù†Ú¯ÛŒ -->

<!-- Meta Description -->
<!-- Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ú©Ø§Ù…Ù„ Ú©Ø§Ø´Øª Ùˆ Ù¾Ø±ÙˆØ±Ø´ Ú¯ÙˆØ¬Ù‡ ÙØ±Ù†Ú¯ÛŒ Ø¨Ø§ Ù†Ú©Ø§Øª Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ø§ØºØ¨Ø§Ù†Ø§Ù† Ø®Ø§Ù†Ú¯ÛŒ. -->

<!-- Content Start -->
<h2>Ù…Ù‚Ø¯Ù…Ù‡</h2>
<p>Ú¯ÙˆØ¬Ù‡ ÙØ±Ù†Ú¯ÛŒ ÛŒÚ©ÛŒ Ø§Ø² Ù…Ø­Ø¨ÙˆØ¨â€ŒØªØ±ÛŒÙ† Ø³Ø¨Ø²ÛŒØ¬Ø§ØªÛŒ Ø§Ø³Øª Ú©Ù‡...</p>

<h2>Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ø°Ø± Ù…Ù†Ø§Ø³Ø¨</h2>
<p>Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø´Øª Ú¯ÙˆØ¬Ù‡ ÙØ±Ù†Ú¯ÛŒØŒ Ø§Ù†ØªØ®Ø§Ø¨ <strong>Ø¨Ø°Ø± Ø¨Ø§ Ú©ÛŒÙÛŒØª</strong> Ø§Ù‡Ù…ÛŒØª Ø²ÛŒØ§Ø¯ÛŒ Ø¯Ø§Ø±Ø¯...</p>
<p>Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² <a href="https://nazboo.com/product-category/seeds/">Ø¨Ø°Ø±Ù‡Ø§ÛŒ Ø¨Ø§Ú©ÛŒÙÛŒØª</a> Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.</p>

<h3>Ø§Ù†ÙˆØ§Ø¹ Ø¨Ø°Ø± Ú¯ÙˆØ¬Ù‡ ÙØ±Ù†Ú¯ÛŒ</h3>
<ul>
  <li>Ú¯ÙˆØ¬Ù‡ ÙØ±Ù†Ú¯ÛŒ Ø±Ù‚Ù… Ù‚Ø¯ÛŒÙ…Ø§</li>
  <li><a href="https://nazboo.com/product/tomato-seed-superb/">Ø¨Ø°Ø± Ú¯ÙˆØ¬Ù‡ ÙØ±Ù†Ú¯ÛŒ Ø³ÙˆÙ¾Ø±Ø¨</a></li>
  <li>Ú¯ÙˆØ¬Ù‡ ÙØ±Ù†Ú¯ÛŒ Ú¯ÛŒÙ„Ø§Ø³ÛŒ</li>
</ul>
...
<!-- Content End -->
```

---

### Test Mode

Test mode limits processing to 10 items for quick validation:

```bash
# Test content optimization
python3 main.py --mode content --test

# Test SEO scraping
python3 main.py --mode scraping --test
```

**When to use**:
- First time setup
- Testing new sitemaps
- Validating configuration
- Quick checks before full run

---

## âš™ï¸ Configuration

### Multi-Model AI Configuration âœ¨ NEW

Starting from v2.3.0, you can configure multiple AI models and choose which one to use for each operation.

**Configuration in `config.yaml`**:

```yaml
# Multi-Model AI Configuration
ai_models:
  # Set default model
  default: "liara_gpt4o_mini"
  
  # Configure multiple models
  liara_gpt4o_mini:
    provider: "openai_compatible"
    api_key: "your-liara-api-key"
    base_url: "https://ai.liara.ir/api/YOUR_PROJECT/v1"
    model: "openai/gpt-4o-mini"
    
  openai_gpt4:
    provider: "openai"
    api_key: "env:OPENAI_API_KEY"  # Read from environment variable
    base_url: "https://api.openai.com/v1"
    model: "gpt-4"
  
  claude_sonnet:
    provider: "anthropic"
    api_key: "env:ANTHROPIC_API_KEY"
    model: "claude-3-5-sonnet-20241022"
  
  gemini_pro:
    provider: "gemini"
    api_key: "env:GOOGLE_API_KEY"
    model: "gemini-pro"
  
  grok_llama3_70b:
    provider: "grok"
    api_key: "env:GROK_API_KEY"
    model: "llama3-70b-8192"
```

**Supported Providers**:

| Provider | Type | Models | Configuration |
|----------|------|--------|---------------|
| **OpenAI** | `openai` | GPT-4, GPT-4o, GPT-3.5 | `api_key`, `base_url`, `model` |
| **Claude** | `anthropic` | Claude 3 (Opus, Sonnet, Haiku) | `api_key`, `model` |
| **Gemini** | `gemini` | Gemini Pro, Gemini Pro Vision | `api_key`, `model` |
| **Grok** | `grok` | Llama 3, Mixtral | `api_key`, `model` |
| **Liara.ir** | `openai_compatible` | Any OpenAI-compatible | `api_key`, `base_url`, `model` |
| **Custom** | `openai_compatible` | Any OpenAI-compatible API | `api_key`, `base_url`, `model` |

**Environment Variables**:
You can use `env:VARIABLE_NAME` to read API keys from environment variables:

```bash
# Set environment variables
export OPENAI_API_KEY="sk-your-openai-key"
export ANTHROPIC_API_KEY="sk-ant-your-claude-key"
export GOOGLE_API_KEY="your-google-api-key"
export GROK_API_KEY="gsk_your-grok-key"

# Run the tool
python3 main.py --mode generation
```

**Model Selection Flow**:
1. At startup, system tests all configured models
2. User chooses: "Use default for all" or "Select per operation"
3. If "Select per operation", system prompts for model selection when needed
4. Only connected models are shown in selection

**Example Model Selection**:
```bash
ğŸ¤– Select AI Model for: Content Generation
======================================================================

  [1] liara_gpt4o_mini (openai_compatible) [DEFAULT]
  [2] claude_sonnet (anthropic)
  [3] gemini_pro (gemini)

  [0] Use default model (liara_gpt4o_mini)

----------------------------------------------------------------------

Your selection: 2
âœ… Selected: claude_sonnet
```

---

### Legacy AI Provider Setup (v2.2.3 and earlier)

**OpenAI**:
```yaml
ai:
  provider: openai
  model: gpt-4o-mini
  openai_api_key: "sk-your-key"
  openai_base_url: "https://api.openai.com/v1"
```

**Liara.ir (OpenAI-Compatible)**:
```yaml
ai:
  provider: openai_compatible
  model: openai/gpt-4o-mini
  compatible_base_url: "https://ai.liara.ir/api/PROJECT_ID/v1"
  compatible_api_key: "your-key"
```

**Azure OpenAI**:
```yaml
ai:
  provider: azure
  model: gpt-4o-mini
  azure_endpoint: "https://resource.openai.azure.com"
  azure_api_key: "your-key"
  azure_deployment: "gpt-4o-mini"
```

### App Settings

```yaml
app:
  min_position: 10              # Minimum position for opportunities
  clustering_threshold: 0.7     # Keyword clustering similarity
  max_headings_per_article: 8   # Max H2/H3 suggestions
  output_directory: "output"    # Output folder
```

---

## ğŸ”§ Troubleshooting

### "No Excel files found"
**Solution**: Copy your Search Console Excel files to the `input/` folder:
```bash
cp ~/Downloads/search_console_data.xlsx input/
```

### "Sitemap download failed"
**Solution**: The tool will retry 10 times automatically. Check:
- Internet connection
- Sitemap URL is correct and accessible
- No firewall blocking requests

### "API key not configured"
**Solution**: Edit `config.yaml` and add your actual API key:
```yaml
compatible_api_key: "actual-key-not-placeholder"
```

### "Missing required columns"
**Solution**: Ensure Excel export includes: `Top queries`, `Clicks`, `Impressions`, `CTR`, `Position`

### Scraping interrupted
**Solution**: Just run again! The tool will resume from where it stopped:
```bash
python3 main.py --mode scraping
# Select same sitemap, it will skip already scraped pages
```

---

## ğŸ“Š Example Workflows

### Workflow 1: Monthly Content Audit
```bash
# 1. Export fresh Search Console data
# 2. Run analysis
python3 main.py --mode content

# 3. Implement top 10 suggestions
# 4. Track results next month
```

### Workflow 2: Complete SEO Audit
```bash
# 1. Scrape all pages
python3 main.py --mode scraping

# 2. Export data, identify issues
# 3. Fix missing/duplicate titles
# 4. Re-scrape to verify fixes
```

### Workflow 3: New Content Strategy
```bash
# 1. Analyze Search Console
python3 main.py --mode content

# 2. Review new_content_*.xlsx
# 3. Create articles based on AI outlines
# 4. Track rankings in 30 days
```

### Workflow 4: AI Content Generation with Internal Linking âœ¨ NEW
```bash
# 1. Analyze Search Console and get content ideas
python3 main.py --mode content

# 2. Generate full content with AI
python3 main.py --mode generation
#    - Select the new_content_*.xlsx file
#    - Choose AI model (Claude, GPT-4, Gemini, etc.)
#    - Set word count per article (e.g., 800 words)
#    - Enable internal linking with sitemap

# 3. Review generated content in:
#    - Excel: output/content_generated/
#    - Word docs: output/documents/
#    - HTML files: output/documents/

# 4. Publish content and track results
```

---

# Ù…Ø³ØªÙ†Ø¯Ø§Øª ÙØ§Ø±Ø³ÛŒ

## ğŸš€ Ø´Ø±ÙˆØ¹ Ø³Ø±ÛŒØ¹

### Û±. Ù†ØµØ¨ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§
```bash
pip install -r requirements.txt
```

### Û². Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ API
ÙØ§ÛŒÙ„ `config.yaml` Ø±Ø§ ÙˆÛŒØ±Ø§ÛŒØ´ Ú©Ù†ÛŒØ¯:
```yaml
ai:
  provider: openai_compatible
  model: openai/gpt-4o-mini
  compatible_base_url: "https://ai.liara.ir/api/Ø´Ù†Ø§Ø³Ù‡_Ù¾Ø±ÙˆÚ˜Ù‡/v1"
  compatible_api_key: "Ú©Ù„ÛŒØ¯_API_Ø´Ù…Ø§"
```

### Û³. Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡
- ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ú©Ø³Ù„ Ø±Ø§ Ø¯Ø± Ù¾ÙˆØ´Ù‡ `input/` Ú©Ù¾ÛŒ Ú©Ù†ÛŒØ¯
- Ø¢Ø¯Ø±Ø³ sitemap Ø®ÙˆØ¯ Ø±Ø§ Ø¢Ù…Ø§Ø¯Ù‡ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´ÛŒØ¯

### Û´. Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡
```bash
# Ø­Ø§Ù„Øª ØªØ¹Ø§Ù…Ù„ÛŒ (Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ† Ø¨Ø§Ø±)
python3 main.py

# Ù…Ø³ØªÙ‚ÛŒÙ… Ø­Ø§Ù„Øª Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø­ØªÙˆØ§
python3 main.py --mode content

# Ø­Ø§Ù„Øª Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ SEO
python3 main.py --mode scraping

# Ø­Ø§Ù„Øª ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ âœ¨ Ø¬Ø¯ÛŒØ¯
python3 main.py --mode generation

# Ø­Ø§Ù„Øª ØªØ³Øª (Û±Û° Ø¢ÛŒØªÙ…)
python3 main.py --mode content --test
```

### Ûµ. ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ v2.1 âœ¨

**ØªØ­Ù„ÛŒÙ„ ÙØ§Ø±Ø³ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ´Ø¯Ù‡:**
- AI Ø¨Ø§ Ø¯Ø±Ú© Ø¹Ù…ÛŒÙ‚ Ø§Ø² Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ
- Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ÛŒ LSI Ù…Ø®ØµÙˆØµ ÙØ§Ø±Ø³ÛŒ
- Ø³Ø§Ø®ØªØ§Ø± Ù…Ø­ØªÙˆØ§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø¬Ø³ØªØ¬ÙˆÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ
- ØªÙˆØ¬Ù‡ Ø¨Ù‡ Featured Snippet ÙØ§Ø±Ø³ÛŒ

**Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ù†Ø´ Ù‡ÙˆØ´Ù…Ù†Ø¯:**
```bash
# Ø¯Ø± Ø§ÙˆÙ„ÛŒÙ† Ø§Ø¬Ø±Ø§ØŒ Ù†Ø§Ù… Ù¾Ø±ÙˆÚ˜Ù‡ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯
Project name: example.com

# Ø³ÛŒØ³ØªÙ… Ø®ÙˆØ¯Ú©Ø§Ø±:
# âœ… ØªÙ…Ø§Ù… Ù…Ø­ØªÙˆØ§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ Ø±Ø§ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
# âœ… Ø§Ø² ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
# âœ… Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ Ø±Ø§ Ù¾ÛŒÚ¯ÛŒØ±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
# âœ… Ù…Ø¯Ù„ Ø±Ø§ Ø¨Ø§ Ø²Ù…Ø§Ù† Ø¨Ù‡Ø¨ÙˆØ¯ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯
```

**Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ù†Ø´:**
```bash
ls knowledge_base/example.com/
# metadata.json              # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ù„ÛŒ
# content_history.json       # Ù…Ø­ØªÙˆØ§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡
# performance_metrics.json   # Ø¹Ù…Ù„Ú©Ø±Ø¯
# keyword_clusters.json      # Ú©Ù„Ø§Ø³ØªØ±Ù‡Ø§
```

---

## ğŸ¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§

### Ø­Ø§Ù„Øª Û±: Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø­ØªÙˆØ§ (ÙØ§Ø±Ø³ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ´Ø¯Ù‡) ğŸ‡®ğŸ‡·
- **ØªØ­Ù„ÛŒÙ„ Search Console**: Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú¯ÙˆÚ¯Ù„
- **Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ÙØ±ØµØªâ€ŒÙ‡Ø§**: ÛŒØ§ÙØªÙ† Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ù¾ØªØ§Ù†Ø³ÛŒÙ„
- **AI ÙØ§Ø±Ø³ÛŒ**: 
  - Ø¯Ø±Ú© Ø¹Ù…ÛŒÙ‚ Ø§Ø² Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ùˆ Ù†Ú¯Ø§Ø±Ø´â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
  - ØªØ­Ù„ÛŒÙ„ search intent Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø§ÛŒØ±Ø§Ù†ÛŒ
  - Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ÛŒ LSI Ù…Ø®ØµÙˆØµ ÙØ§Ø±Ø³ÛŒ
  - ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø­Ù„ÛŒ
- **Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¬Ø§Ù…Ø¹**:
  - Ø¹Ù†ÙˆØ§Ù† Ùˆ Ù…ØªØ§ Ø¯ÛŒØ³Ú©Ø±ÛŒÙ¾Ø´Ù† Ø¨Ù‡ÛŒÙ†Ù‡ (Û¶Û° Ùˆ Û±Û¶Û° Ú©Ø§Ø±Ø§Ú©ØªØ±)
  - Ø³Ø§Ø®ØªØ§Ø± H2/H3 Ù…Ø·Ø§Ø¨Ù‚ Ø¨Ø§ Ø¬Ø³ØªØ¬ÙˆÙ‡Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ
  - Ø³ÙˆØ§Ù„Ø§Øª Ù…ØªØ¯Ø§ÙˆÙ„ (FAQ) Ø¨ÙˆÙ…ÛŒâ€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡
  - Internal linking Ø¨Ø§ anchor text ÙØ§Ø±Ø³ÛŒ
  - Schema markup Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ
- **Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ù†Ø´ Ù‡ÙˆØ´Ù…Ù†Ø¯**:
  - Ø°Ø®ÛŒØ±Ù‡ Ø®ÙˆØ¯Ú©Ø§Ø± ØªÙ…Ø§Ù… Ù…Ø­ØªÙˆØ§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡
  - Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ
  - ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø§Ø² Ø¹Ù…Ù„Ú©Ø±Ø¯ Ú¯Ø°Ø´ØªÙ‡

### Ø­Ø§Ù„Øª Û²: Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ SEO
- **Scraping ØµÙØ­Ø§Øª**: Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªØ§ÛŒØªÙ„ØŒ ØªÙˆØ¶ÛŒØ­Ø§ØªØŒ H1
- **Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ**: Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø§ Ú©Ù†ØªØ±Ù„ Ùˆ Ù‚Ø§Ø¨Ù„ÛŒØª ØªÙˆÙ‚Ù/Ø§Ø¯Ø§Ù…Ù‡
- **Ù¾ÛŒÚ¯ÛŒØ±ÛŒ Ù¾ÛŒØ´Ø±ÙØª**: Ù†ÙˆØ§Ø± Ù¾ÛŒØ´Ø±ÙØª Ùˆ Ø¢Ù…Ø§Ø± real-time
- **Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§**: ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ Ø®ÙˆØ¯Ú©Ø§Ø±
- **Ù‚Ø§Ø¨Ù„ÛŒØª Ø§Ø¯Ø§Ù…Ù‡**: Ø§Ø¯Ø§Ù…Ù‡ Ø§Ø² Ø¬Ø§ÛŒÛŒ Ú©Ù‡ Ù…ØªÙˆÙ‚Ù Ø´Ø¯Ù‡

### ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø´ØªØ±Ú©
- **Ù…Ø¯ÛŒØ±ÛŒØª Ù‡ÙˆØ´Ù…Ù†Ø¯ Sitemap**:
  - Ø°Ø®ÛŒØ±Ù‡ Ø®ÙˆØ¯Ú©Ø§Ø± (Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¬Ø¯Ø¯)
  - Û±Û° Ø¨Ø§Ø± ØªÙ„Ø§Ø´ Ø¨Ø§ backoff
  - Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² sitemap index
  - Ø§Ù†ØªØ®Ø§Ø¨ Ø¯Ø³ØªÛŒ Ú©Ø§Ø±Ø¨Ø±

- **Ù…Ø¯ÛŒØ±ÛŒØª ÙØ§ÛŒÙ„**:
  - Ø§Ù†ØªØ®Ø§Ø¨ Ú†Ù†Ø¯ ÙØ§ÛŒÙ„ Ø§Ø² `input/`
  - Ù†Ù…Ø§ÛŒØ´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙØ§ÛŒÙ„
  - Ù¾Ø´ØªÛŒØ¨Ø§Ù†â€ŒÚ¯ÛŒØ±ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø±

- **Ø­Ø§Ù„Øª ØªØ³Øª**: Ù…Ø­Ø¯ÙˆØ¯ Ø¨Ù‡ Û±Û° Ø¢ÛŒØªÙ… Ø¨Ø±Ø§ÛŒ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ
- **Ú¯Ø²Ø§Ø±Ø´â€ŒØ¯Ù‡ÛŒ**: Ø°Ø®ÛŒØ±Ù‡ logs Ø¯Ø± `seo_optimizer.log`
- **Ú†Ù†Ø¯ Ø§Ø±Ø§Ø¦Ù‡â€ŒØ¯Ù‡Ù†Ø¯Ù‡ AI**: OpenAIØŒ AzureØŒ AnthropicØŒ Ù„ÛŒØ§Ø±Ø§

---

## ğŸ“¦ Ù†ØµØ¨

### Ù¾ÛŒØ´â€ŒÙ†ÛŒØ§Ø²Ù‡Ø§
- Python 3.8 ÛŒØ§ Ø¨Ø§Ù„Ø§ØªØ±
- pip
- Ø§ØªØµØ§Ù„ Ø§ÛŒÙ†ØªØ±Ù†Øª Ø¨Ø±Ø§ÛŒ API

### Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ
```bash
# Ù†ØµØ¨ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§
pip install -r requirements.txt

# Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ
cp config.sample.yaml config.yaml

# ÙˆÛŒØ±Ø§ÛŒØ´ Ùˆ Ø§ÙØ²ÙˆØ¯Ù† Ú©Ù„ÛŒØ¯ API
nano config.yaml
```

### Ø³Ø§Ø®ØªØ§Ø± Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§
```
SEOContentAnalysis/
â”œâ”€â”€ input/              # ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ú©Ø³Ù„ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯
â”œâ”€â”€ sitemaps/           # sitemap Ù‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡
â”œâ”€â”€ output/             # Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ
â”œâ”€â”€ main.py             # Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§ØµÙ„ÛŒ
â”œâ”€â”€ config.yaml         # Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø´Ù…Ø§
â””â”€â”€ src/                # Ù…Ø§Ú˜ÙˆÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø¨Ø¹
```

---

## ğŸ® Ø§Ø³ØªÙØ§Ø¯Ù‡

### Ø­Ø§Ù„Øª Û±: Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø­ØªÙˆØ§

**Ù‡Ø¯Ù**: ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Search Console Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ù…Ø­ØªÙˆØ§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ùˆ ÛŒØ§ÙØªÙ† ÙØ±ØµØªâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯.

**Ù…Ø±Ø§Ø­Ù„**:
1. Export Ø§Ø² Google Search Console (Performance â†’ Export)
2. Ú©Ù¾ÛŒ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø¨Ù‡ Ù¾ÙˆØ´Ù‡ `input/`
3. Ø§Ø¬Ø±Ø§: `python3 main.py --mode content`
4. Ø§Ù†ØªØ®Ø§Ø¨ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
5. ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† Ø¢Ø¯Ø±Ø³ sitemap
6. Ù…Ù†ØªØ¸Ø± ØªØ­Ù„ÛŒÙ„ AI
7. Ø¨Ø±Ø±Ø³ÛŒ Ù†ØªØ§ÛŒØ¬ Ø¯Ø± `output/`

**ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ**:
- `improvements_[filename].xlsx` - Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ø±Ø§ÛŒ ØµÙØ­Ø§Øª Ù…ÙˆØ¬ÙˆØ¯
- `new_content_[filename].xlsx` - Ø§ÛŒØ¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§Ù„Ø§Øª Ø¬Ø¯ÛŒØ¯

---

### Ø­Ø§Ù„Øª Û²: Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ SEO

**Ù‡Ø¯Ù**: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ùˆ Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ SEO ØªÙ…Ø§Ù… ØµÙØ­Ø§Øª Ø³Ø§ÛŒØª.

**Ù…Ø±Ø§Ø­Ù„**:
1. Ø§Ø¬Ø±Ø§: `python3 main.py --mode scraping`
2. ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† Ø¢Ø¯Ø±Ø³ sitemap
3. Ø§Ù†ØªØ®Ø§Ø¨ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø¯Ø³ØªÙ‡ (Ù…Ø«Ù„Ø§ ÛµÛ° ØµÙØ­Ù‡)
4. Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ø± Ø¯Ø³ØªÙ‡ Ùˆ Ø§Ø¯Ø§Ù…Ù‡ ÛŒØ§ ØªÙˆÙ‚Ù
5. Ù†ØªØ§ÛŒØ¬ Ø¯Ø± `output/seo_data_[domain].xlsx`

**Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø´Ø¯Ù‡**:
- Ø¢Ø¯Ø±Ø³ URL
- ØªÚ¯ Title
- Meta description
- Ø³Ø±ÙØµÙ„ H1
- Canonical URL
- ØªÚ¯â€ŒÙ‡Ø§ÛŒ Open Graph
- ØªÚ¯â€ŒÙ‡Ø§ÛŒ Twitter Card

---

### Ø­Ø§Ù„Øª Û³: ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ âœ¨ Ø¬Ø¯ÛŒØ¯

**Ù‡Ø¯Ù**: ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ÛŒ SEO Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ´Ø¯Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒØŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ú†Ù†Ø¯ Ù…Ø¯Ù„ Ùˆ Ù„ÛŒÙ†Ú©â€ŒØ¯Ù‡ÛŒ Ø¯Ø§Ø®Ù„ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø±.

**ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ**:
- **Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ú†Ù†Ø¯ Ù…Ø¯Ù„ AI**: Ø§Ù†ØªØ®Ø§Ø¨ Ø§Ø² Ø¨ÛŒÙ† OpenAIØŒ ClaudeØŒ GeminiØŒ Grok Ùˆ ØºÛŒØ±Ù‡
- **Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ SEO ÙØ§Ø±Ø³ÛŒ**: Ù…Ø­ØªÙˆØ§ Ø¨Ø§ Ø±Ø¹Ø§ÛŒØª Ø§ØµÙˆÙ„ SEO ÙØ§Ø±Ø³ÛŒ
- **Ù„ÛŒÙ†Ú©â€ŒØ¯Ù‡ÛŒ Ø¯Ø§Ø®Ù„ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯**:
  - Û± Ù„ÛŒÙ†Ú© Ø¨Ù‡ Ø§Ø²Ø§ÛŒ Ù‡Ø± Û³Û°Û°-Û´Û°Û° Ú©Ù„Ù…Ù‡
  - Ø¹Ø¯Ù… Ù„ÛŒÙ†Ú© Ø¯Ø± Ù‡Ø¯ÛŒÙ†Ú¯â€ŒÙ‡Ø§
  - Ø§ÙˆÙ„ÙˆÛŒØª: Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ > Ù…Ø­ØµÙˆÙ„Ø§Øª > Ù…Ù‚Ø§Ù„Ø§Øª
  - Ø§Ù†Ú©Ø± ØªÚ©Ø³Øª Ø³Ù…Ù†ØªÛŒÚ© (Ø­Ø¯Ø§Ú©Ø«Ø± Ûµ Ù‡Ø¬Ø§)
- **Ø®Ø±ÙˆØ¬ÛŒ Ú†Ù†Ø¯Ú¯Ø§Ù†Ù‡**:
  - Ø§Ú©Ø³Ù„: Ø¨Ø§ Ø¹Ù†ÙˆØ§Ù† SEOØŒ Ù…ØªØ§ Ø¯ÛŒØ³Ú©Ø±ÛŒÙ¾Ø´Ù† Ùˆ Ù…Ø­ØªÙˆØ§
  - Word: Ø§Ø³Ù†Ø§Ø¯ ÙØ±Ù…Øªâ€ŒØ¨Ù†Ø¯ÛŒ Ø´Ø¯Ù‡
  - HTML: Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø¯ÛŒØªÙˆØ± (Ø¨Ø¯ÙˆÙ† ØªÚ¯â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡)

**Ù…Ø­ØªÙˆØ§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ Ø´Ø§Ù…Ù„**:
- Ø¹Ù†ÙˆØ§Ù† Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ´Ø¯Ù‡ SEO (Ø­Ø¯Ø§Ú©Ø«Ø± Û¶Û° Ú©Ø§Ø±Ø§Ú©ØªØ±)
- Ù…ØªØ§ Ø¯ÛŒØ³Ú©Ø±ÛŒÙ¾Ø´Ù† (Ø­Ø¯Ø§Ú©Ø«Ø± Û±Û¶Û° Ú©Ø§Ø±Ø§Ú©ØªØ±)
- Ù…Ø­ØªÙˆØ§ÛŒ Ú©Ø§Ù…Ù„ HTML Ø¨Ø§ Ø³Ø§Ø®ØªØ§Ø± Ù…Ù†Ø§Ø³Ø¨ (H2, H3, Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§ÙØŒ Ù„ÛŒØ³Øª)
- Ù†Ú¯Ø§Ø±Ø´ Ø·Ø¨ÛŒØ¹ÛŒ ÙØ§Ø±Ø³ÛŒ Ø¨Ø§ Ø§ØµÙˆÙ„ E-E-A-T
- ØªÙ†ÙˆØ¹ Ø¯Ø± ÙØ§ØµÙ„Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø·Ø¨ÛŒØ¹ÛŒâ€ŒØªØ± Ø¨ÙˆØ¯Ù†

**Ù…Ø±Ø§Ø­Ù„ Ø§Ø¬Ø±Ø§**:
1. Ø§Ø¬Ø±Ø§: `python3 main.py --mode generation`
2. Ø³ÛŒØ³ØªÙ… ØªÙ…Ø§Ù… Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ AI Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø´Ø¯Ù‡ Ø±Ø§ ØªØ³Øª Ù…ÛŒâ€ŒÚ©Ù†Ø¯
3. Ø§Ù†ØªØ®Ø§Ø¨ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ ÛŒØ§ Ø§Ù†ØªØ®Ø§Ø¨ Ø¯Ø³ØªÛŒ
4. **Ø§Ù†ØªØ®Ø§Ø¨ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø§Ø² Ù¾ÙˆØ´Ù‡ `output/`** (ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ Ø§Ø² Ø­Ø§Ù„Øª Û±)
5. ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† Ù†Ø§Ù… Ù¾Ø±ÙˆÚ˜Ù‡
6. Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„ AI Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§
7. **Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø±Ø¯ÛŒÙ Ù…Ù‚Ø§Ù„Ù‡**:
   - Ø³ÛŒØ³ØªÙ… Ù…ÙˆØ¶ÙˆØ¹ Ø±Ø§ Ø§Ø² Ø³ØªÙˆÙ† Ø§ÙˆÙ„ Ù†Ù…Ø§ÛŒØ´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯
   - ØªÙ…Ø§Ù… Ù‡Ø¯ÛŒÙ†Ú¯â€ŒÙ‡Ø§ Ø§Ø² Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø± Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
   - Ø¯Ø±Ø®ÙˆØ§Ø³Øª ØªØ§ÛŒÛŒØ¯
   - Ù¾Ø±Ø³Ø´ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„Ù…Ø§Øª Ú©Ù„ Ù…Ù‚Ø§Ù„Ù‡
   - Ù¾Ø±Ø³Ø´ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„Ù…Ø§Øª Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù‡Ø¯ÛŒÙ†Ú¯
   - ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù‡Ø¯ÛŒÙ†Ú¯
   - ØªÙˆÙ„ÛŒØ¯ Ù…Ù‚Ø¯Ù…Ù‡ Ùˆ Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ
   - ØªØ±Ú©ÛŒØ¨ Ø¯Ø± ÛŒÚ© Ù…Ù‚Ø§Ù„Ù‡ Ú©Ø§Ù…Ù„
8. Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø®Ù„ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ sitemap (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
9. Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ù‡ ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Word Ùˆ HTML

**ØªÙˆØ¬Ù‡**: 
- ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ú©Ø³Ù„ Ø§Ø² Ù¾ÙˆØ´Ù‡ `output/` Ø®ÙˆØ§Ù†Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ (Ø®Ø±ÙˆØ¬ÛŒ Ø­Ø§Ù„Øª Û±)
- Ø±Ø¯ÛŒÙ Ø§ÙˆÙ„ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø³Ø±Ø³ØªÙˆÙ† Ø¯Ø± Ù†Ø¸Ø± Ú¯Ø±ÙØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
- **Ø³ØªÙˆÙ† Û±**: Ù…ÙˆØ¶ÙˆØ¹ Ù…Ù‚Ø§Ù„Ù‡ (Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯)
- **Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Û²-Û¶**: Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ (Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒØŒ Ú©Ù„Ø§Ø³ØªØ±ØŒ Ù†ÙˆØ¹ Ù…Ø­ØªÙˆØ§ØŒ Ù‡Ø¯Ù Ø¬Ø³ØªØ¬ÙˆØŒ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„Ù…Ø§Øª)
- **Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Û·+**: Ù‡Ø¯ÛŒÙ†Ú¯â€ŒÙ‡Ø§ÛŒ H2 (ÙÙ‚Ø· Ø§ÛŒÙ†â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯)
- Ù‡Ø± Ø±Ø¯ÛŒÙ ÛŒÚ© Ù…Ù‚Ø§Ù„Ù‡ Ú©Ø§Ù…Ù„ Ø§Ø³Øª

**Ù…Ø«Ø§Ù„ Ø³Ø§Ø®ØªØ§Ø± Ø§Ú©Ø³Ù„**:
| Ø¹Ù†ÙˆØ§Ù† Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ù…Ù‚Ø§Ù„Ù‡ | Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†Ù…Ø§ÛŒØ´ | Ú©Ù„Ø§Ø³ØªØ± Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡ | Ù†ÙˆØ¹ Ù…Ø­ØªÙˆØ§ | Ù‡Ø¯Ù Ø¬Ø³ØªØ¬Ùˆ | ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„Ù…Ø§Øª | Ù‡Ø¯ÛŒÙ†Ú¯ H2 Ø´Ù…Ø§Ø±Ù‡ 1 | Ù‡Ø¯ÛŒÙ†Ú¯ H2 Ø´Ù…Ø§Ø±Ù‡ 2 | ... |
|---------------------|-------------|-------------|---------|---------|-----------|-----------------|-----------------|-----|
| Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ú©Ø§Ø´Øª Ú¯Ù„Ù‡Ø§ | 1500 | Ú©Ø§Ø´Øª | Ø±Ø§Ù‡Ù†Ù…Ø§ | Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ | 2000 | Ù…Ø¹Ø±ÙÛŒ Ú¯Ù„ Ù„ÛŒÙ„ÛŒÙˆÙ… | Ù†Ø­ÙˆÙ‡ Ú©Ø§Ø´Øª | ... |

**Ù…Ø«Ø§Ù„ Ø®Ø±ÙˆØ¬ÛŒ Ø§Ú©Ø³Ù„**:

| Ø¹Ù†ÙˆØ§Ù† Ø§ØµÙ„ÛŒ | H2_1 | H2_2 | SEO_Title | Meta_Description | Generated_Content |
|-----------|------|------|-----------|-----------------|-------------------|
| Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ú©Ø§Ø´Øª Ú¯ÙˆØ¬Ù‡ ÙØ±Ù†Ú¯ÛŒ | Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ø°Ø± | Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø®Ø§Ú© | Ø¨Ù‡ØªØ±ÛŒÙ† Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø´Øª Ú¯ÙˆØ¬Ù‡ ÙØ±Ù†Ú¯ÛŒ... | Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ú©Ø§Ù…Ù„ Ú©Ø§Ø´Øª Ùˆ Ù¾Ø±ÙˆØ±Ø´... | `<h2>Ù…Ù‚Ø¯Ù…Ù‡</h2><p>...</p>...` |

**Ø³Ø§Ø®ØªØ§Ø± Ø§Ø³Ù†Ø§Ø¯ Word**:
```
Ø§Ø·Ù„Ø§Ø¹Ø§Øª SEO
-----------
Ø¹Ù†ÙˆØ§Ù†: Ø¨Ù‡ØªØ±ÛŒÙ† Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø´Øª Ú¯ÙˆØ¬Ù‡ ÙØ±Ù†Ú¯ÛŒ Ø¯Ø± Ø¨Ø§Øº Ø®Ø§Ù†Ú¯ÛŒ
Ù…ØªØ§ Ø¯ÛŒØ³Ú©Ø±ÛŒÙ¾Ø´Ù†: Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ú©Ø§Ù…Ù„ Ú©Ø§Ø´Øª Ùˆ Ù¾Ø±ÙˆØ±Ø´ Ú¯ÙˆØ¬Ù‡ ÙØ±Ù†Ú¯ÛŒ Ø¨Ø§ Ù†Ú©Ø§Øª Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ...

___________________________________________________________

Ù…Ø­ØªÙˆØ§
-----
[Ù…Ø­ØªÙˆØ§ÛŒ Ú©Ø§Ù…Ù„ Ø¨Ø§ ÙØ±Ù…Øªâ€ŒØ¨Ù†Ø¯ÛŒØŒ Ù‡Ø¯ÛŒÙ†Ú¯â€ŒÙ‡Ø§ØŒ Ù…ØªÙ†â€ŒÙ‡Ø§ÛŒ Ø¨ÙˆÙ„Ø¯ Ùˆ ØºÛŒØ±Ù‡]
```

**Ø®Ø±ÙˆØ¬ÛŒ HTML** (Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø¯ÛŒØªÙˆØ±):
```html
<!-- SEO Title -->
<!-- Ø¨Ù‡ØªØ±ÛŒÙ† Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø´Øª Ú¯ÙˆØ¬Ù‡ ÙØ±Ù†Ú¯ÛŒ Ø¯Ø± Ø¨Ø§Øº Ø®Ø§Ù†Ú¯ÛŒ -->

<!-- Meta Description -->
<!-- Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ú©Ø§Ù…Ù„ Ú©Ø§Ø´Øª Ùˆ Ù¾Ø±ÙˆØ±Ø´ Ú¯ÙˆØ¬Ù‡ ÙØ±Ù†Ú¯ÛŒ Ø¨Ø§ Ù†Ú©Ø§Øª Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ -->

<!-- Content Start -->
<h2>Ù…Ù‚Ø¯Ù…Ù‡</h2>
<p>Ú¯ÙˆØ¬Ù‡ ÙØ±Ù†Ú¯ÛŒ ÛŒÚ©ÛŒ Ø§Ø² Ù…Ø­Ø¨ÙˆØ¨â€ŒØªØ±ÛŒÙ† Ø³Ø¨Ø²ÛŒØ¬Ø§Øª...</p>

<h2>Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ø°Ø± Ù…Ù†Ø§Ø³Ø¨</h2>
<p>Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø´Øª Ù…ÙˆÙÙ‚ØŒ <strong>Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ø°Ø± Ø¨Ø§Ú©ÛŒÙÛŒØª</strong> Ø¶Ø±ÙˆØ±ÛŒ Ø§Ø³Øª...</p>
<p>Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² <a href="https://example.com/category/seeds/">Ø¨Ø°Ø±Ù‡Ø§ÛŒ Ø¨Ø§Ú©ÛŒÙÛŒØª</a> Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.</p>
...
<!-- Content End -->
```

---

### Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ú†Ù†Ø¯ Ù…Ø¯Ù„ AI

Ø§Ø² Ù†Ø³Ø®Ù‡ v2.3.0ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ú†Ù†Ø¯ÛŒÙ† Ù…Ø¯Ù„ AI Ø±Ø§ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ú©Ø±Ø¯Ù‡ Ùˆ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¹Ù…Ù„ÛŒØ§Øª ÛŒÚ©ÛŒ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯.

**Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø¯Ø± `config.yaml`**:

```yaml
ai_models:
  # Ù…Ø¯Ù„ Ù¾ÛŒØ´â€ŒÙØ±Ø¶
  default: "liara_gpt4o_mini"
  
  # Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ú†Ù†Ø¯ Ù…Ø¯Ù„
  liara_gpt4o_mini:
    provider: "openai_compatible"
    api_key: "Ú©Ù„ÛŒØ¯-API-Ù„ÛŒØ§Ø±Ø§"
    base_url: "https://ai.liara.ir/api/Ù¾Ø±ÙˆÚ˜Ù‡/v1"
    model: "openai/gpt-4o-mini"
    
  claude_sonnet:
    provider: "anthropic"
    api_key: "env:ANTHROPIC_API_KEY"
    model: "claude-3-5-sonnet-20241022"
  
  gemini_pro:
    provider: "gemini"
    api_key: "env:GOOGLE_API_KEY"
    model: "gemini-pro"
```

**ØªÙ†Ø¸ÛŒÙ… Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ**:
```bash
export OPENAI_API_KEY="Ú©Ù„ÛŒØ¯-OpenAI"
export ANTHROPIC_API_KEY="Ú©Ù„ÛŒØ¯-Claude"
export GOOGLE_API_KEY="Ú©Ù„ÛŒØ¯-Google"
export GROK_API_KEY="Ú©Ù„ÛŒØ¯-Grok"
```

---

### Ø­Ø§Ù„Øª ØªØ³Øª

Ø¨Ø±Ø§ÛŒ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø³Ø±ÛŒØ¹ Ø¨Ø§ Û±Û° Ø¢ÛŒØªÙ…:

```bash
# ØªØ³Øª Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø­ØªÙˆØ§
python3 main.py --mode content --test

# ØªØ³Øª scraping
python3 main.py --mode scraping --test
```

**Ú†Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒÙ…**:
- Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø§ÙˆÙ„ÛŒÙ‡
- ØªØ³Øª sitemap Ø¬Ø¯ÛŒØ¯
- Ø¨Ø±Ø±Ø³ÛŒ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ
- Ú†Ú© Ø³Ø±ÛŒØ¹ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø§Ù…Ù„

---

## ğŸ”§ Ø±ÙØ¹ Ù…Ø´Ú©Ù„Ø§Øª

### "Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯"
**Ø±Ø§Ù‡â€ŒØ­Ù„**: ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ø¯Ø± Ù¾ÙˆØ´Ù‡ `input/` Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯:
```bash
cp ~/Downloads/search_console_data.xlsx input/
```

### "Ø¯Ø§Ù†Ù„ÙˆØ¯ sitemap Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯"
**Ø±Ø§Ù‡â€ŒØ­Ù„**: Ø¨Ø±Ù†Ø§Ù…Ù‡ Û±Û° Ø¨Ø§Ø± ØªÙ„Ø§Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯:
- Ø§ØªØµØ§Ù„ Ø§ÛŒÙ†ØªØ±Ù†Øª
- ØµØ­Øª Ø¢Ø¯Ø±Ø³ sitemap
- ÙØ§ÛŒØ±ÙˆØ§Ù„

### "Ú©Ù„ÛŒØ¯ API Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ù†Ø´Ø¯Ù‡"
**Ø±Ø§Ù‡â€ŒØ­Ù„**: `config.yaml` Ø±Ø§ ÙˆÛŒØ±Ø§ÛŒØ´ Ú©Ù†ÛŒØ¯:
```yaml
compatible_api_key: "Ú©Ù„ÛŒØ¯-ÙˆØ§Ù‚Ø¹ÛŒ-Ù†Ù‡-placeholder"
```

### Scraping Ù…ØªÙˆÙ‚Ù Ø´Ø¯
**Ø±Ø§Ù‡â€ŒØ­Ù„**: Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯! Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ø² Ø¬Ø§ÛŒÛŒ Ú©Ù‡ Ù…ØªÙˆÙ‚Ù Ø´Ø¯Ù‡ Ø§Ø¯Ø§Ù…Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.

---

## ğŸ“„ Ù…Ø¬ÙˆØ²

MIT License

---

**Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡ Ø¨Ø§ â¤ï¸ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ SEO**

